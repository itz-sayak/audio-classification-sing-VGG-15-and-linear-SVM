# -*- coding: utf-8 -*-
"""Audio Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1U5LeVM9Z5n_izCt2DmuwzbAsNfWmlkPa
"""

!pip install pydub

from pytube import YouTube

yt = YouTube('https://www.youtube.com/watch?v=PPdNb-XQXR8')
yt.streams.filter(only_audio=True).first().download()

from pytube import YouTube

yt = YouTube('https://www.youtube.com/watch?v=sRdRwHPjJPk')
yt.streams.filter(only_audio=True).first().download()

# Converting Audio Files from .mp3 to .wav
from pydub import AudioSegment
sound = AudioSegment.from_mp3("/content/bike.mp3")
sound.export("bike.wav", format="wav")

# Extracting Chunks of Audios
from pydub import AudioSegment
import os
if not os.path.exists("bike"):
    os.makedirs("bike")

# Converting Audio Files from .mp3 to .wav
from pydub import AudioSegment
sound = AudioSegment.from_mp3("/content/car.mp3")
sound.export("car.wav", format="wav")

# Extracting Chunks of Audios
from pydub import AudioSegment
import os
if not os.path.exists("car"):
    os.makedirs("car")

count = 1
for i in range(1, 1000, 15):
    t1 = i * 1000  # Works in milliseconds
    t2 = (i + 15) * 1000
    newAudio = AudioSegment.from_wav("bike.wav")
    newAudio = newAudio[t1:t2]
    newAudio.export('bike/' + str(count) + '.wav', format="wav")  # Exports to a wav file in the current path.
    print(count)
    count += 1

count=1
for i in range(1,1000,15):
    t1 = i * 1000 #Works in milliseconds
    t2 = (i+15) * 1000
    newAudio = AudioSegment.from_wav("car.wav")
    newAudio = newAudio[t1:t2]
    newAudio.export('car/'+str(count)+'.wav', format="wav") #Exports to a wav file in the current path.
    print(count)
    count+=1

# Plotting Amplitude Waveforms
from scipy.io.wavfile import read
import matplotlib.pyplot as plt
from os import walk
import os

if not os.path.exists("carPlots"):
    os.makedirs("carPlots")

car_wavs = []
for (_,_,filenames) in walk('car'):
    car_wavs.extend(filenames)
    break
for car_wav in car_wavs:
    # read audio samples
    input_data = read("car/" + car_wav)
    audio = input_data[1]
    # plot the first 1024 samples
    plt.plot(audio)
    # label the axes
    plt.ylabel("Amplitude")
    plt.xlabel("Time")
    # set the title
    # plt.title("Sample Wav")
    # display the plot
    plt.savefig("carPlots/" + car_wav.split('.')[0] + '.png')
    # plt.show()
    plt.close('all')

# Plotting Amplitude Waveforms
from scipy.io.wavfile import read
import matplotlib.pyplot as plt
from os import walk
import os
if not os.path.exists("bikePlots"):
    os.makedirs("bikePlots")
bike_wavs = []
for (_, _, filenames) in walk('bike'):
    bike_wavs.extend(filenames)
    break
for bike_wav in bike_wavs:
    # read audio samples
    input_data = read("bike/" + bike_wav)
    audio = input_data[1]
    # plot the first 1024 samples
    plt.plot(audio)
    # label the axes
    plt.ylabel("Amplitude")
    plt.xlabel("Time")
    # set the title
    # plt.title("Sample Wav")
    # display the plot
    plt.savefig("bikePlots/" + bike_wav.split('.')[0] + '.png')
    # plt.show()
    plt.close('all')

# Extracting Features and Training LinearSVM
import os
from keras.applications.vgg19 import VGG19
from keras.preprocessing import image
from keras.applications.vgg19 import preprocess_input
from keras.models import Model
import numpy as np

base_model = VGG19(weights='imagenet')
model = Model(inputs=base_model.input, outputs=base_model.get_layer('flatten').output)

def get_features(img_path):
    img = image.load_img(img_path, target_size=(224, 224))
    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=0)
    x = preprocess_input(x)
    flatten = model.predict(x)
    return list(flatten[0])

X = []
y = []

bike_plots = []
for (_,_,filenames) in os.walk('bikePlots'):
    bike_plots.extend(filenames)
    break

for cplot in bike_plots:
    X.append(get_features('bikePlots/' + cplot))
    y.append(1)

non_bike_plots = []
for (_,_,filenames) in os.walk('carPlots'):
    non_bike_plots.extend(filenames)
    break

for cplot in non_bike_plots:
    X.append(get_features('carPlots/' + cplot))
    y.append(0)

from sklearn.model_selection import train_test_split
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.model_selection import GridSearchCV

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)

# Define hyperparameters for grid search
param_grid = {
    'C': [0.1, 1, 10],
    'penalty': ['l1', 'l2'],
    'max_iter': [1000, 5000, 10000]
}

# Perform grid search
grid_search = GridSearchCV(LinearSVC(random_state=0, tol=1e-5), param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)

# Get the best model
best_model = grid_search.best_estimator_

# Evaluate the best model
y_pred = best_model.predict(X_test)
print("Best Model Parameters: ", grid_search.best_params_)
print("Best Model Accuracy: ", grid_search.best_score_)
print("Best Model Confusion Matrix: ")
print(confusion_matrix(y_test, y_pred))
print("Best Model Classification Report: ")
print(classification_report(y_test, y_pred))

import pickle

# Define the best model
best_model = grid_search.best_estimator_

# Save the best model to a .pkl file
with open('best_model.pkl', 'wb') as f:
    pickle.dump(best_model, f)

